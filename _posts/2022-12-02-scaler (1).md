---
title:  "[Python] 데이터전처리-표준화.정규화" 

categories:
  - python
tags:
  - [Python,ADP,class101]

toc: true
toc_sticky: true

date: 2022-12-02

---

# 데이터 표준화와 정규화

ex) 10km 10m 

ex) 평균이 1000인 집단에서 1의 차이 평균이 100인 집단에서 1의 차이 

sklearn에서는 다양한 종류의 스케일러를 제공함 

* <b>데이터 변환이 필요한 이유 </b>
- 데이터의 단위와 평균과 표준편차가 모두 다르다면, 머신이 그 단위를 인지하지 못함 
- 또한 통계는 표본집단의 평균과 분산으로 모집단의 분산을 설명하는 학문->차원의 스케일 맞추기 중요 


```python
import pandas as pd
import numpy as np
```

## 표준화 시키기StandardScaler

**표준화가 되고 나서 (0,1) 평균0 표준편차1**

z = (x - u) / s

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(data) : 모델 학습 

transform을 시킬때는 데이터의 평균과 표준편차로 transform뒤의 데이터를 다 표준화 시켜준다 (scaler.transform(data))



```python
from sklearn.preprocessing import StandardScaler

# 2차원 데이터 생성

data=[[0,0],[0,0],[1,1],[1,1]]
data

# data의 평균은 2/4 =0.5이다 
# 실제로는 이런 느낌으로 세로 생성됨

# 00
# 00
# 11
# 11
```




    [[0, 0], [0, 0], [1, 1], [1, 1]]




```python
# scaler의 데이터를 학습시킨다(Fit을 해줌)
# mean과 var 생김 

scaler = StandardScaler()
print(scaler.fit(data))
```

    StandardScaler()
    


```python
print(scaler.mean_)
```

    [0.5 0.5]
    


```python
# var계산방법
# (-0.5)^2+(-0.5)^2+(-0.5)^2+(-0.5)^2 / 4 =1/4=0.25

#이때 표준편차는 0.5가 됨 
# 계산식 S^2=(0.25)^2=0.5

scaler.var_
```




    array([0.25, 0.25])




```python
# 모든데이터에 (x - M) / s 함
# 모든데이터에 -0.5하고  /0.5 나눠줌 

# 평균 0 표준편차 1 이어야함 

print(scaler.transform(data))
```

    [[-1. -1.]
     [-1. -1.]
     [ 1.  1.]
     [ 1.  1.]]
    


```python
# (2-0.5)/0.5=3
print(scaler.transform([[2,2]]))
```

    [[3. 3.]]
    

## 표준화 예제

iris데이터에서 target은 숫자가 아니기때문에 사용 어려움 


```python
import pandas as pd 
iris=pd.read_csv('D:/anaconda/00.studying/data/iris.csv')
```


```python
scaler = StandardScaler()
```


```python
iris
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length</th>
      <th>sepal width</th>
      <th>petal length</th>
      <th>petal width</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5.1</td>
      <td>3.5</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>1</th>
      <td>4.9</td>
      <td>3.0</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4.7</td>
      <td>3.2</td>
      <td>1.3</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4.6</td>
      <td>3.1</td>
      <td>1.5</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.0</td>
      <td>3.6</td>
      <td>1.4</td>
      <td>0.2</td>
      <td>Iris-setosa</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>6.7</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.3</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <th>146</th>
      <td>6.3</td>
      <td>2.5</td>
      <td>5.0</td>
      <td>1.9</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <th>147</th>
      <td>6.5</td>
      <td>3.0</td>
      <td>5.2</td>
      <td>2.0</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <th>148</th>
      <td>6.2</td>
      <td>3.4</td>
      <td>5.4</td>
      <td>2.3</td>
      <td>Iris-virginica</td>
    </tr>
    <tr>
      <th>149</th>
      <td>5.9</td>
      <td>3.0</td>
      <td>5.1</td>
      <td>1.8</td>
      <td>Iris-virginica</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 5 columns</p>
</div>



# iloc와 loc차이

loc는 칼럼명or특정 조건식으로 데이터 접근한다면

iloc는 컴퓨터 읽기 좋은 방식으로 접근 df.iloc[행인덱스,열 인덱스]


```python
# 필요한 데이터만 가져와서 fit시켜주기
# 행은 다가져오고 열은 target 빼기 
scaler.fit(iris.iloc[:,0:4])
```




<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler()</pre></div></div></div></div></div>




```python
scaler.mean_
```




    array([5.84333333, 3.054     , 3.75866667, 1.19866667])




```python
scaler.var_
```




    array([0.68112222, 0.18675067, 3.09242489, 0.57853156])



세번째 열 값에  -1.19866667 / √0.57853156


```python
# 값 변환
scaler.transform(iris.iloc[:,0:4])
```




    array([[-9.00681170e-01,  1.03205722e+00, -1.34127240e+00,
            -1.31297673e+00],
           [-1.14301691e+00, -1.24957601e-01, -1.34127240e+00,
            -1.31297673e+00],
           [-1.38535265e+00,  3.37848329e-01, -1.39813811e+00,
            -1.31297673e+00],
           [-1.50652052e+00,  1.06445364e-01, -1.28440670e+00,
            -1.31297673e+00],
           [-1.02184904e+00,  1.26346019e+00, -1.34127240e+00,
            -1.31297673e+00],
           [-5.37177559e-01,  1.95766909e+00, -1.17067529e+00,
            -1.05003079e+00],
           [-1.50652052e+00,  8.00654259e-01, -1.34127240e+00,
            -1.18150376e+00],
           [-1.02184904e+00,  8.00654259e-01, -1.28440670e+00,
            -1.31297673e+00],
           [-1.74885626e+00, -3.56360566e-01, -1.34127240e+00,
            -1.31297673e+00],
           [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,
            -1.44444970e+00],
           [-5.37177559e-01,  1.49486315e+00, -1.28440670e+00,
            -1.31297673e+00],
           [-1.26418478e+00,  8.00654259e-01, -1.22754100e+00,
            -1.31297673e+00],
           [-1.26418478e+00, -1.24957601e-01, -1.34127240e+00,
            -1.44444970e+00],
           [-1.87002413e+00, -1.24957601e-01, -1.51186952e+00,
            -1.44444970e+00],
           [-5.25060772e-02,  2.18907205e+00, -1.45500381e+00,
            -1.31297673e+00],
           [-1.73673948e-01,  3.11468391e+00, -1.28440670e+00,
            -1.05003079e+00],
           [-5.37177559e-01,  1.95766909e+00, -1.39813811e+00,
            -1.05003079e+00],
           [-9.00681170e-01,  1.03205722e+00, -1.34127240e+00,
            -1.18150376e+00],
           [-1.73673948e-01,  1.72626612e+00, -1.17067529e+00,
            -1.18150376e+00],
           [-9.00681170e-01,  1.72626612e+00, -1.28440670e+00,
            -1.18150376e+00],
           [-5.37177559e-01,  8.00654259e-01, -1.17067529e+00,
            -1.31297673e+00],
           [-9.00681170e-01,  1.49486315e+00, -1.28440670e+00,
            -1.05003079e+00],
           [-1.50652052e+00,  1.26346019e+00, -1.56873522e+00,
            -1.31297673e+00],
           [-9.00681170e-01,  5.69251294e-01, -1.17067529e+00,
            -9.18557817e-01],
           [-1.26418478e+00,  8.00654259e-01, -1.05694388e+00,
            -1.31297673e+00],
           [-1.02184904e+00, -1.24957601e-01, -1.22754100e+00,
            -1.31297673e+00],
           [-1.02184904e+00,  8.00654259e-01, -1.22754100e+00,
            -1.05003079e+00],
           [-7.79513300e-01,  1.03205722e+00, -1.28440670e+00,
            -1.31297673e+00],
           [-7.79513300e-01,  8.00654259e-01, -1.34127240e+00,
            -1.31297673e+00],
           [-1.38535265e+00,  3.37848329e-01, -1.22754100e+00,
            -1.31297673e+00],
           [-1.26418478e+00,  1.06445364e-01, -1.22754100e+00,
            -1.31297673e+00],
           [-5.37177559e-01,  8.00654259e-01, -1.28440670e+00,
            -1.05003079e+00],
           [-7.79513300e-01,  2.42047502e+00, -1.28440670e+00,
            -1.44444970e+00],
           [-4.16009689e-01,  2.65187798e+00, -1.34127240e+00,
            -1.31297673e+00],
           [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,
            -1.44444970e+00],
           [-1.02184904e+00,  3.37848329e-01, -1.45500381e+00,
            -1.31297673e+00],
           [-4.16009689e-01,  1.03205722e+00, -1.39813811e+00,
            -1.31297673e+00],
           [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,
            -1.44444970e+00],
           [-1.74885626e+00, -1.24957601e-01, -1.39813811e+00,
            -1.31297673e+00],
           [-9.00681170e-01,  8.00654259e-01, -1.28440670e+00,
            -1.31297673e+00],
           [-1.02184904e+00,  1.03205722e+00, -1.39813811e+00,
            -1.18150376e+00],
           [-1.62768839e+00, -1.74477836e+00, -1.39813811e+00,
            -1.18150376e+00],
           [-1.74885626e+00,  3.37848329e-01, -1.39813811e+00,
            -1.31297673e+00],
           [-1.02184904e+00,  1.03205722e+00, -1.22754100e+00,
            -7.87084847e-01],
           [-9.00681170e-01,  1.72626612e+00, -1.05694388e+00,
            -1.05003079e+00],
           [-1.26418478e+00, -1.24957601e-01, -1.34127240e+00,
            -1.18150376e+00],
           [-9.00681170e-01,  1.72626612e+00, -1.22754100e+00,
            -1.31297673e+00],
           [-1.50652052e+00,  3.37848329e-01, -1.34127240e+00,
            -1.31297673e+00],
           [-6.58345429e-01,  1.49486315e+00, -1.28440670e+00,
            -1.31297673e+00],
           [-1.02184904e+00,  5.69251294e-01, -1.34127240e+00,
            -1.31297673e+00],
           [ 1.40150837e+00,  3.37848329e-01,  5.35295827e-01,
             2.64698913e-01],
           [ 6.74501145e-01,  3.37848329e-01,  4.21564419e-01,
             3.96171883e-01],
           [ 1.28034050e+00,  1.06445364e-01,  6.49027235e-01,
             3.96171883e-01],
           [-4.16009689e-01, -1.74477836e+00,  1.37235899e-01,
             1.33225943e-01],
           [ 7.95669016e-01, -5.87763531e-01,  4.78430123e-01,
             3.96171883e-01],
           [-1.73673948e-01, -5.87763531e-01,  4.21564419e-01,
             1.33225943e-01],
           [ 5.53333275e-01,  5.69251294e-01,  5.35295827e-01,
             5.27644853e-01],
           [-1.14301691e+00, -1.51337539e+00, -2.60824029e-01,
            -2.61192967e-01],
           [ 9.16836886e-01, -3.56360566e-01,  4.78430123e-01,
             1.33225943e-01],
           [-7.79513300e-01, -8.19166497e-01,  8.03701950e-02,
             2.64698913e-01],
           [-1.02184904e+00, -2.43898725e+00, -1.47092621e-01,
            -2.61192967e-01],
           [ 6.86617933e-02, -1.24957601e-01,  2.50967307e-01,
             3.96171883e-01],
           [ 1.89829664e-01, -1.97618132e+00,  1.37235899e-01,
            -2.61192967e-01],
           [ 3.10997534e-01, -3.56360566e-01,  5.35295827e-01,
             2.64698913e-01],
           [-2.94841818e-01, -3.56360566e-01, -9.02269170e-02,
             1.33225943e-01],
           [ 1.03800476e+00,  1.06445364e-01,  3.64698715e-01,
             2.64698913e-01],
           [-2.94841818e-01, -1.24957601e-01,  4.21564419e-01,
             3.96171883e-01],
           [-5.25060772e-02, -8.19166497e-01,  1.94101603e-01,
            -2.61192967e-01],
           [ 4.32165405e-01, -1.97618132e+00,  4.21564419e-01,
             3.96171883e-01],
           [-2.94841818e-01, -1.28197243e+00,  8.03701950e-02,
            -1.29719997e-01],
           [ 6.86617933e-02,  3.37848329e-01,  5.92161531e-01,
             7.90590793e-01],
           [ 3.10997534e-01, -5.87763531e-01,  1.37235899e-01,
             1.33225943e-01],
           [ 5.53333275e-01, -1.28197243e+00,  6.49027235e-01,
             3.96171883e-01],
           [ 3.10997534e-01, -5.87763531e-01,  5.35295827e-01,
             1.75297293e-03],
           [ 6.74501145e-01, -3.56360566e-01,  3.07833011e-01,
             1.33225943e-01],
           [ 9.16836886e-01, -1.24957601e-01,  3.64698715e-01,
             2.64698913e-01],
           [ 1.15917263e+00, -5.87763531e-01,  5.92161531e-01,
             2.64698913e-01],
           [ 1.03800476e+00, -1.24957601e-01,  7.05892939e-01,
             6.59117823e-01],
           [ 1.89829664e-01, -3.56360566e-01,  4.21564419e-01,
             3.96171883e-01],
           [-1.73673948e-01, -1.05056946e+00, -1.47092621e-01,
            -2.61192967e-01],
           [-4.16009689e-01, -1.51337539e+00,  2.35044910e-02,
            -1.29719997e-01],
           [-4.16009689e-01, -1.51337539e+00, -3.33612130e-02,
            -2.61192967e-01],
           [-5.25060772e-02, -8.19166497e-01,  8.03701950e-02,
             1.75297293e-03],
           [ 1.89829664e-01, -8.19166497e-01,  7.62758643e-01,
             5.27644853e-01],
           [-5.37177559e-01, -1.24957601e-01,  4.21564419e-01,
             3.96171883e-01],
           [ 1.89829664e-01,  8.00654259e-01,  4.21564419e-01,
             5.27644853e-01],
           [ 1.03800476e+00,  1.06445364e-01,  5.35295827e-01,
             3.96171883e-01],
           [ 5.53333275e-01, -1.74477836e+00,  3.64698715e-01,
             1.33225943e-01],
           [-2.94841818e-01, -1.24957601e-01,  1.94101603e-01,
             1.33225943e-01],
           [-4.16009689e-01, -1.28197243e+00,  1.37235899e-01,
             1.33225943e-01],
           [-4.16009689e-01, -1.05056946e+00,  3.64698715e-01,
             1.75297293e-03],
           [ 3.10997534e-01, -1.24957601e-01,  4.78430123e-01,
             2.64698913e-01],
           [-5.25060772e-02, -1.05056946e+00,  1.37235899e-01,
             1.75297293e-03],
           [-1.02184904e+00, -1.74477836e+00, -2.60824029e-01,
            -2.61192967e-01],
           [-2.94841818e-01, -8.19166497e-01,  2.50967307e-01,
             1.33225943e-01],
           [-1.73673948e-01, -1.24957601e-01,  2.50967307e-01,
             1.75297293e-03],
           [-1.73673948e-01, -3.56360566e-01,  2.50967307e-01,
             1.33225943e-01],
           [ 4.32165405e-01, -3.56360566e-01,  3.07833011e-01,
             1.33225943e-01],
           [-9.00681170e-01, -1.28197243e+00, -4.31421141e-01,
            -1.29719997e-01],
           [-1.73673948e-01, -5.87763531e-01,  1.94101603e-01,
             1.33225943e-01],
           [ 5.53333275e-01,  5.69251294e-01,  1.27454998e+00,
             1.71090158e+00],
           [-5.25060772e-02, -8.19166497e-01,  7.62758643e-01,
             9.22063763e-01],
           [ 1.52267624e+00, -1.24957601e-01,  1.21768427e+00,
             1.18500970e+00],
           [ 5.53333275e-01, -3.56360566e-01,  1.04708716e+00,
             7.90590793e-01],
           [ 7.95669016e-01, -1.24957601e-01,  1.16081857e+00,
             1.31648267e+00],
           [ 2.12851559e+00, -1.24957601e-01,  1.61574420e+00,
             1.18500970e+00],
           [-1.14301691e+00, -1.28197243e+00,  4.21564419e-01,
             6.59117823e-01],
           [ 1.76501198e+00, -3.56360566e-01,  1.44514709e+00,
             7.90590793e-01],
           [ 1.03800476e+00, -1.28197243e+00,  1.16081857e+00,
             7.90590793e-01],
           [ 1.64384411e+00,  1.26346019e+00,  1.33141568e+00,
             1.71090158e+00],
           [ 7.95669016e-01,  3.37848329e-01,  7.62758643e-01,
             1.05353673e+00],
           [ 6.74501145e-01, -8.19166497e-01,  8.76490051e-01,
             9.22063763e-01],
           [ 1.15917263e+00, -1.24957601e-01,  9.90221459e-01,
             1.18500970e+00],
           [-1.73673948e-01, -1.28197243e+00,  7.05892939e-01,
             1.05353673e+00],
           [-5.25060772e-02, -5.87763531e-01,  7.62758643e-01,
             1.57942861e+00],
           [ 6.74501145e-01,  3.37848329e-01,  8.76490051e-01,
             1.44795564e+00],
           [ 7.95669016e-01, -1.24957601e-01,  9.90221459e-01,
             7.90590793e-01],
           [ 2.24968346e+00,  1.72626612e+00,  1.67260991e+00,
             1.31648267e+00],
           [ 2.24968346e+00, -1.05056946e+00,  1.78634131e+00,
             1.44795564e+00],
           [ 1.89829664e-01, -1.97618132e+00,  7.05892939e-01,
             3.96171883e-01],
           [ 1.28034050e+00,  3.37848329e-01,  1.10395287e+00,
             1.44795564e+00],
           [-2.94841818e-01, -5.87763531e-01,  6.49027235e-01,
             1.05353673e+00],
           [ 2.24968346e+00, -5.87763531e-01,  1.67260991e+00,
             1.05353673e+00],
           [ 5.53333275e-01, -8.19166497e-01,  6.49027235e-01,
             7.90590793e-01],
           [ 1.03800476e+00,  5.69251294e-01,  1.10395287e+00,
             1.18500970e+00],
           [ 1.64384411e+00,  3.37848329e-01,  1.27454998e+00,
             7.90590793e-01],
           [ 4.32165405e-01, -5.87763531e-01,  5.92161531e-01,
             7.90590793e-01],
           [ 3.10997534e-01, -1.24957601e-01,  6.49027235e-01,
             7.90590793e-01],
           [ 6.74501145e-01, -5.87763531e-01,  1.04708716e+00,
             1.18500970e+00],
           [ 1.64384411e+00, -1.24957601e-01,  1.16081857e+00,
             5.27644853e-01],
           [ 1.88617985e+00, -5.87763531e-01,  1.33141568e+00,
             9.22063763e-01],
           [ 2.49201920e+00,  1.72626612e+00,  1.50201279e+00,
             1.05353673e+00],
           [ 6.74501145e-01, -5.87763531e-01,  1.04708716e+00,
             1.31648267e+00],
           [ 5.53333275e-01, -5.87763531e-01,  7.62758643e-01,
             3.96171883e-01],
           [ 3.10997534e-01, -1.05056946e+00,  1.04708716e+00,
             2.64698913e-01],
           [ 2.24968346e+00, -1.24957601e-01,  1.33141568e+00,
             1.44795564e+00],
           [ 5.53333275e-01,  8.00654259e-01,  1.04708716e+00,
             1.57942861e+00],
           [ 6.74501145e-01,  1.06445364e-01,  9.90221459e-01,
             7.90590793e-01],
           [ 1.89829664e-01, -1.24957601e-01,  5.92161531e-01,
             7.90590793e-01],
           [ 1.28034050e+00,  1.06445364e-01,  9.33355755e-01,
             1.18500970e+00],
           [ 1.03800476e+00,  1.06445364e-01,  1.04708716e+00,
             1.57942861e+00],
           [ 1.28034050e+00,  1.06445364e-01,  7.62758643e-01,
             1.44795564e+00],
           [-5.25060772e-02, -8.19166497e-01,  7.62758643e-01,
             9.22063763e-01],
           [ 1.15917263e+00,  3.37848329e-01,  1.21768427e+00,
             1.44795564e+00],
           [ 1.03800476e+00,  5.69251294e-01,  1.10395287e+00,
             1.71090158e+00],
           [ 1.03800476e+00, -1.24957601e-01,  8.19624347e-01,
             1.44795564e+00],
           [ 5.53333275e-01, -1.28197243e+00,  7.05892939e-01,
             9.22063763e-01],
           [ 7.95669016e-01, -1.24957601e-01,  8.19624347e-01,
             1.05353673e+00],
           [ 4.32165405e-01,  8.00654259e-01,  9.33355755e-01,
             1.44795564e+00],
           [ 6.86617933e-02, -1.24957601e-01,  7.62758643e-01,
             7.90590793e-01]])




```python
# 값을 데이터프레임으로 만들기 
# 컬럼값 안넣으면 그냥 0,1,2,3이 나와서 columns=iris.columns[0:4]정해줌
pd.DataFrame(scaler.transform(iris.iloc[:,0:4]),
             columns=iris.columns[0:4]
             +"_scaled")
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sepal length_scaled</th>
      <th>sepal width_scaled</th>
      <th>petal length_scaled</th>
      <th>petal width_scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.900681</td>
      <td>1.032057</td>
      <td>-1.341272</td>
      <td>-1.312977</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.143017</td>
      <td>-0.124958</td>
      <td>-1.341272</td>
      <td>-1.312977</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.385353</td>
      <td>0.337848</td>
      <td>-1.398138</td>
      <td>-1.312977</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-1.506521</td>
      <td>0.106445</td>
      <td>-1.284407</td>
      <td>-1.312977</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-1.021849</td>
      <td>1.263460</td>
      <td>-1.341272</td>
      <td>-1.312977</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>145</th>
      <td>1.038005</td>
      <td>-0.124958</td>
      <td>0.819624</td>
      <td>1.447956</td>
    </tr>
    <tr>
      <th>146</th>
      <td>0.553333</td>
      <td>-1.281972</td>
      <td>0.705893</td>
      <td>0.922064</td>
    </tr>
    <tr>
      <th>147</th>
      <td>0.795669</td>
      <td>-0.124958</td>
      <td>0.819624</td>
      <td>1.053537</td>
    </tr>
    <tr>
      <th>148</th>
      <td>0.432165</td>
      <td>0.800654</td>
      <td>0.933356</td>
      <td>1.447956</td>
    </tr>
    <tr>
      <th>149</th>
      <td>0.068662</td>
      <td>-0.124958</td>
      <td>0.762759</td>
      <td>0.790591</td>
    </tr>
  </tbody>
</table>
<p>150 rows × 4 columns</p>
</div>



## 정규화 시키기 MinMaxScaler

최대/최소값이 각각 1,0이 되도록 스케일링한다
 
X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))

->열별로 계산됨. 범위를 0~1로 만들어줌 

X_scaled = X_std * (max - min) + min

sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)


```python
from sklearn.preprocessing import MinMaxScaler
data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]
# -1   2
# -0.5 6
# 0   10
#1    18
scaler = MinMaxScaler()
print(scaler.fit(data))

print(scaler.data_max_)
```

    MinMaxScaler()
    [ 1. 18.]
    


```python
scaler.data_min_
```




    array([-1.,  2.])




```python
print(scaler.transform(data))
```

    [[0.   0.  ]
     [0.25 0.25]
     [0.5  0.5 ]
     [1.   1.  ]]
    

## iris데이터로 정규화해보기 

fit된 데이터를 transform한다는게 중요하다 


```python
scaler = MinMaxScaler()
print(scaler.fit(iris.iloc[:,0:4]))
```

    MinMaxScaler()
    


```python
scaler.data_min_
```




    array([4.3, 2. , 1. , 0.1])




```python
scaler.data_max_
```




    array([7.9, 4.4, 6.9, 2.5])




```python
scaler.transform(iris.iloc[:,0:4])
```




    array([[0.22222222, 0.625     , 0.06779661, 0.04166667],
           [0.16666667, 0.41666667, 0.06779661, 0.04166667],
           [0.11111111, 0.5       , 0.05084746, 0.04166667],
           [0.08333333, 0.45833333, 0.08474576, 0.04166667],
           [0.19444444, 0.66666667, 0.06779661, 0.04166667],
           [0.30555556, 0.79166667, 0.11864407, 0.125     ],
           [0.08333333, 0.58333333, 0.06779661, 0.08333333],
           [0.19444444, 0.58333333, 0.08474576, 0.04166667],
           [0.02777778, 0.375     , 0.06779661, 0.04166667],
           [0.16666667, 0.45833333, 0.08474576, 0.        ],
           [0.30555556, 0.70833333, 0.08474576, 0.04166667],
           [0.13888889, 0.58333333, 0.10169492, 0.04166667],
           [0.13888889, 0.41666667, 0.06779661, 0.        ],
           [0.        , 0.41666667, 0.01694915, 0.        ],
           [0.41666667, 0.83333333, 0.03389831, 0.04166667],
           [0.38888889, 1.        , 0.08474576, 0.125     ],
           [0.30555556, 0.79166667, 0.05084746, 0.125     ],
           [0.22222222, 0.625     , 0.06779661, 0.08333333],
           [0.38888889, 0.75      , 0.11864407, 0.08333333],
           [0.22222222, 0.75      , 0.08474576, 0.08333333],
           [0.30555556, 0.58333333, 0.11864407, 0.04166667],
           [0.22222222, 0.70833333, 0.08474576, 0.125     ],
           [0.08333333, 0.66666667, 0.        , 0.04166667],
           [0.22222222, 0.54166667, 0.11864407, 0.16666667],
           [0.13888889, 0.58333333, 0.15254237, 0.04166667],
           [0.19444444, 0.41666667, 0.10169492, 0.04166667],
           [0.19444444, 0.58333333, 0.10169492, 0.125     ],
           [0.25      , 0.625     , 0.08474576, 0.04166667],
           [0.25      , 0.58333333, 0.06779661, 0.04166667],
           [0.11111111, 0.5       , 0.10169492, 0.04166667],
           [0.13888889, 0.45833333, 0.10169492, 0.04166667],
           [0.30555556, 0.58333333, 0.08474576, 0.125     ],
           [0.25      , 0.875     , 0.08474576, 0.        ],
           [0.33333333, 0.91666667, 0.06779661, 0.04166667],
           [0.16666667, 0.45833333, 0.08474576, 0.        ],
           [0.19444444, 0.5       , 0.03389831, 0.04166667],
           [0.33333333, 0.625     , 0.05084746, 0.04166667],
           [0.16666667, 0.45833333, 0.08474576, 0.        ],
           [0.02777778, 0.41666667, 0.05084746, 0.04166667],
           [0.22222222, 0.58333333, 0.08474576, 0.04166667],
           [0.19444444, 0.625     , 0.05084746, 0.08333333],
           [0.05555556, 0.125     , 0.05084746, 0.08333333],
           [0.02777778, 0.5       , 0.05084746, 0.04166667],
           [0.19444444, 0.625     , 0.10169492, 0.20833333],
           [0.22222222, 0.75      , 0.15254237, 0.125     ],
           [0.13888889, 0.41666667, 0.06779661, 0.08333333],
           [0.22222222, 0.75      , 0.10169492, 0.04166667],
           [0.08333333, 0.5       , 0.06779661, 0.04166667],
           [0.27777778, 0.70833333, 0.08474576, 0.04166667],
           [0.19444444, 0.54166667, 0.06779661, 0.04166667],
           [0.75      , 0.5       , 0.62711864, 0.54166667],
           [0.58333333, 0.5       , 0.59322034, 0.58333333],
           [0.72222222, 0.45833333, 0.66101695, 0.58333333],
           [0.33333333, 0.125     , 0.50847458, 0.5       ],
           [0.61111111, 0.33333333, 0.61016949, 0.58333333],
           [0.38888889, 0.33333333, 0.59322034, 0.5       ],
           [0.55555556, 0.54166667, 0.62711864, 0.625     ],
           [0.16666667, 0.16666667, 0.38983051, 0.375     ],
           [0.63888889, 0.375     , 0.61016949, 0.5       ],
           [0.25      , 0.29166667, 0.49152542, 0.54166667],
           [0.19444444, 0.        , 0.42372881, 0.375     ],
           [0.44444444, 0.41666667, 0.54237288, 0.58333333],
           [0.47222222, 0.08333333, 0.50847458, 0.375     ],
           [0.5       , 0.375     , 0.62711864, 0.54166667],
           [0.36111111, 0.375     , 0.44067797, 0.5       ],
           [0.66666667, 0.45833333, 0.57627119, 0.54166667],
           [0.36111111, 0.41666667, 0.59322034, 0.58333333],
           [0.41666667, 0.29166667, 0.52542373, 0.375     ],
           [0.52777778, 0.08333333, 0.59322034, 0.58333333],
           [0.36111111, 0.20833333, 0.49152542, 0.41666667],
           [0.44444444, 0.5       , 0.6440678 , 0.70833333],
           [0.5       , 0.33333333, 0.50847458, 0.5       ],
           [0.55555556, 0.20833333, 0.66101695, 0.58333333],
           [0.5       , 0.33333333, 0.62711864, 0.45833333],
           [0.58333333, 0.375     , 0.55932203, 0.5       ],
           [0.63888889, 0.41666667, 0.57627119, 0.54166667],
           [0.69444444, 0.33333333, 0.6440678 , 0.54166667],
           [0.66666667, 0.41666667, 0.6779661 , 0.66666667],
           [0.47222222, 0.375     , 0.59322034, 0.58333333],
           [0.38888889, 0.25      , 0.42372881, 0.375     ],
           [0.33333333, 0.16666667, 0.47457627, 0.41666667],
           [0.33333333, 0.16666667, 0.45762712, 0.375     ],
           [0.41666667, 0.29166667, 0.49152542, 0.45833333],
           [0.47222222, 0.29166667, 0.69491525, 0.625     ],
           [0.30555556, 0.41666667, 0.59322034, 0.58333333],
           [0.47222222, 0.58333333, 0.59322034, 0.625     ],
           [0.66666667, 0.45833333, 0.62711864, 0.58333333],
           [0.55555556, 0.125     , 0.57627119, 0.5       ],
           [0.36111111, 0.41666667, 0.52542373, 0.5       ],
           [0.33333333, 0.20833333, 0.50847458, 0.5       ],
           [0.33333333, 0.25      , 0.57627119, 0.45833333],
           [0.5       , 0.41666667, 0.61016949, 0.54166667],
           [0.41666667, 0.25      , 0.50847458, 0.45833333],
           [0.19444444, 0.125     , 0.38983051, 0.375     ],
           [0.36111111, 0.29166667, 0.54237288, 0.5       ],
           [0.38888889, 0.41666667, 0.54237288, 0.45833333],
           [0.38888889, 0.375     , 0.54237288, 0.5       ],
           [0.52777778, 0.375     , 0.55932203, 0.5       ],
           [0.22222222, 0.20833333, 0.33898305, 0.41666667],
           [0.38888889, 0.33333333, 0.52542373, 0.5       ],
           [0.55555556, 0.54166667, 0.84745763, 1.        ],
           [0.41666667, 0.29166667, 0.69491525, 0.75      ],
           [0.77777778, 0.41666667, 0.83050847, 0.83333333],
           [0.55555556, 0.375     , 0.77966102, 0.70833333],
           [0.61111111, 0.41666667, 0.81355932, 0.875     ],
           [0.91666667, 0.41666667, 0.94915254, 0.83333333],
           [0.16666667, 0.20833333, 0.59322034, 0.66666667],
           [0.83333333, 0.375     , 0.89830508, 0.70833333],
           [0.66666667, 0.20833333, 0.81355932, 0.70833333],
           [0.80555556, 0.66666667, 0.86440678, 1.        ],
           [0.61111111, 0.5       , 0.69491525, 0.79166667],
           [0.58333333, 0.29166667, 0.72881356, 0.75      ],
           [0.69444444, 0.41666667, 0.76271186, 0.83333333],
           [0.38888889, 0.20833333, 0.6779661 , 0.79166667],
           [0.41666667, 0.33333333, 0.69491525, 0.95833333],
           [0.58333333, 0.5       , 0.72881356, 0.91666667],
           [0.61111111, 0.41666667, 0.76271186, 0.70833333],
           [0.94444444, 0.75      , 0.96610169, 0.875     ],
           [0.94444444, 0.25      , 1.        , 0.91666667],
           [0.47222222, 0.08333333, 0.6779661 , 0.58333333],
           [0.72222222, 0.5       , 0.79661017, 0.91666667],
           [0.36111111, 0.33333333, 0.66101695, 0.79166667],
           [0.94444444, 0.33333333, 0.96610169, 0.79166667],
           [0.55555556, 0.29166667, 0.66101695, 0.70833333],
           [0.66666667, 0.54166667, 0.79661017, 0.83333333],
           [0.80555556, 0.5       , 0.84745763, 0.70833333],
           [0.52777778, 0.33333333, 0.6440678 , 0.70833333],
           [0.5       , 0.41666667, 0.66101695, 0.70833333],
           [0.58333333, 0.33333333, 0.77966102, 0.83333333],
           [0.80555556, 0.41666667, 0.81355932, 0.625     ],
           [0.86111111, 0.33333333, 0.86440678, 0.75      ],
           [1.        , 0.75      , 0.91525424, 0.79166667],
           [0.58333333, 0.33333333, 0.77966102, 0.875     ],
           [0.55555556, 0.33333333, 0.69491525, 0.58333333],
           [0.5       , 0.25      , 0.77966102, 0.54166667],
           [0.94444444, 0.41666667, 0.86440678, 0.91666667],
           [0.55555556, 0.58333333, 0.77966102, 0.95833333],
           [0.58333333, 0.45833333, 0.76271186, 0.70833333],
           [0.47222222, 0.41666667, 0.6440678 , 0.70833333],
           [0.72222222, 0.45833333, 0.74576271, 0.83333333],
           [0.66666667, 0.45833333, 0.77966102, 0.95833333],
           [0.72222222, 0.45833333, 0.69491525, 0.91666667],
           [0.41666667, 0.29166667, 0.69491525, 0.75      ],
           [0.69444444, 0.5       , 0.83050847, 0.91666667],
           [0.66666667, 0.54166667, 0.79661017, 1.        ],
           [0.66666667, 0.41666667, 0.71186441, 0.91666667],
           [0.55555556, 0.20833333, 0.6779661 , 0.75      ],
           [0.61111111, 0.41666667, 0.71186441, 0.79166667],
           [0.52777778, 0.58333333, 0.74576271, 0.91666667],
           [0.44444444, 0.41666667, 0.69491525, 0.70833333]])




```python
## model에 fit 된 데이터를 기반으로 학습되며, 추가 데이터에는 비율이 적용됨 
print(scaler.transform([[2, 2,40,450]]))
```

    [[ -0.63888889   0.           6.61016949 187.45833333]]
    

    D:\anaconda\lib\site-packages\sklearn\base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names
      warnings.warn(
    


```python
# ★★fit과 transform을 같이해주는 함수도 있음 ★★
scaler.fit_transform(iris.iloc[:,0:4])
```




    array([[0.22222222, 0.625     , 0.06779661, 0.04166667],
           [0.16666667, 0.41666667, 0.06779661, 0.04166667],
           [0.11111111, 0.5       , 0.05084746, 0.04166667],
           [0.08333333, 0.45833333, 0.08474576, 0.04166667],
           [0.19444444, 0.66666667, 0.06779661, 0.04166667],
           [0.30555556, 0.79166667, 0.11864407, 0.125     ],
           [0.08333333, 0.58333333, 0.06779661, 0.08333333],
           [0.19444444, 0.58333333, 0.08474576, 0.04166667],
           [0.02777778, 0.375     , 0.06779661, 0.04166667],
           [0.16666667, 0.45833333, 0.08474576, 0.        ],
           [0.30555556, 0.70833333, 0.08474576, 0.04166667],
           [0.13888889, 0.58333333, 0.10169492, 0.04166667],
           [0.13888889, 0.41666667, 0.06779661, 0.        ],
           [0.        , 0.41666667, 0.01694915, 0.        ],
           [0.41666667, 0.83333333, 0.03389831, 0.04166667],
           [0.38888889, 1.        , 0.08474576, 0.125     ],
           [0.30555556, 0.79166667, 0.05084746, 0.125     ],
           [0.22222222, 0.625     , 0.06779661, 0.08333333],
           [0.38888889, 0.75      , 0.11864407, 0.08333333],
           [0.22222222, 0.75      , 0.08474576, 0.08333333],
           [0.30555556, 0.58333333, 0.11864407, 0.04166667],
           [0.22222222, 0.70833333, 0.08474576, 0.125     ],
           [0.08333333, 0.66666667, 0.        , 0.04166667],
           [0.22222222, 0.54166667, 0.11864407, 0.16666667],
           [0.13888889, 0.58333333, 0.15254237, 0.04166667],
           [0.19444444, 0.41666667, 0.10169492, 0.04166667],
           [0.19444444, 0.58333333, 0.10169492, 0.125     ],
           [0.25      , 0.625     , 0.08474576, 0.04166667],
           [0.25      , 0.58333333, 0.06779661, 0.04166667],
           [0.11111111, 0.5       , 0.10169492, 0.04166667],
           [0.13888889, 0.45833333, 0.10169492, 0.04166667],
           [0.30555556, 0.58333333, 0.08474576, 0.125     ],
           [0.25      , 0.875     , 0.08474576, 0.        ],
           [0.33333333, 0.91666667, 0.06779661, 0.04166667],
           [0.16666667, 0.45833333, 0.08474576, 0.        ],
           [0.19444444, 0.5       , 0.03389831, 0.04166667],
           [0.33333333, 0.625     , 0.05084746, 0.04166667],
           [0.16666667, 0.45833333, 0.08474576, 0.        ],
           [0.02777778, 0.41666667, 0.05084746, 0.04166667],
           [0.22222222, 0.58333333, 0.08474576, 0.04166667],
           [0.19444444, 0.625     , 0.05084746, 0.08333333],
           [0.05555556, 0.125     , 0.05084746, 0.08333333],
           [0.02777778, 0.5       , 0.05084746, 0.04166667],
           [0.19444444, 0.625     , 0.10169492, 0.20833333],
           [0.22222222, 0.75      , 0.15254237, 0.125     ],
           [0.13888889, 0.41666667, 0.06779661, 0.08333333],
           [0.22222222, 0.75      , 0.10169492, 0.04166667],
           [0.08333333, 0.5       , 0.06779661, 0.04166667],
           [0.27777778, 0.70833333, 0.08474576, 0.04166667],
           [0.19444444, 0.54166667, 0.06779661, 0.04166667],
           [0.75      , 0.5       , 0.62711864, 0.54166667],
           [0.58333333, 0.5       , 0.59322034, 0.58333333],
           [0.72222222, 0.45833333, 0.66101695, 0.58333333],
           [0.33333333, 0.125     , 0.50847458, 0.5       ],
           [0.61111111, 0.33333333, 0.61016949, 0.58333333],
           [0.38888889, 0.33333333, 0.59322034, 0.5       ],
           [0.55555556, 0.54166667, 0.62711864, 0.625     ],
           [0.16666667, 0.16666667, 0.38983051, 0.375     ],
           [0.63888889, 0.375     , 0.61016949, 0.5       ],
           [0.25      , 0.29166667, 0.49152542, 0.54166667],
           [0.19444444, 0.        , 0.42372881, 0.375     ],
           [0.44444444, 0.41666667, 0.54237288, 0.58333333],
           [0.47222222, 0.08333333, 0.50847458, 0.375     ],
           [0.5       , 0.375     , 0.62711864, 0.54166667],
           [0.36111111, 0.375     , 0.44067797, 0.5       ],
           [0.66666667, 0.45833333, 0.57627119, 0.54166667],
           [0.36111111, 0.41666667, 0.59322034, 0.58333333],
           [0.41666667, 0.29166667, 0.52542373, 0.375     ],
           [0.52777778, 0.08333333, 0.59322034, 0.58333333],
           [0.36111111, 0.20833333, 0.49152542, 0.41666667],
           [0.44444444, 0.5       , 0.6440678 , 0.70833333],
           [0.5       , 0.33333333, 0.50847458, 0.5       ],
           [0.55555556, 0.20833333, 0.66101695, 0.58333333],
           [0.5       , 0.33333333, 0.62711864, 0.45833333],
           [0.58333333, 0.375     , 0.55932203, 0.5       ],
           [0.63888889, 0.41666667, 0.57627119, 0.54166667],
           [0.69444444, 0.33333333, 0.6440678 , 0.54166667],
           [0.66666667, 0.41666667, 0.6779661 , 0.66666667],
           [0.47222222, 0.375     , 0.59322034, 0.58333333],
           [0.38888889, 0.25      , 0.42372881, 0.375     ],
           [0.33333333, 0.16666667, 0.47457627, 0.41666667],
           [0.33333333, 0.16666667, 0.45762712, 0.375     ],
           [0.41666667, 0.29166667, 0.49152542, 0.45833333],
           [0.47222222, 0.29166667, 0.69491525, 0.625     ],
           [0.30555556, 0.41666667, 0.59322034, 0.58333333],
           [0.47222222, 0.58333333, 0.59322034, 0.625     ],
           [0.66666667, 0.45833333, 0.62711864, 0.58333333],
           [0.55555556, 0.125     , 0.57627119, 0.5       ],
           [0.36111111, 0.41666667, 0.52542373, 0.5       ],
           [0.33333333, 0.20833333, 0.50847458, 0.5       ],
           [0.33333333, 0.25      , 0.57627119, 0.45833333],
           [0.5       , 0.41666667, 0.61016949, 0.54166667],
           [0.41666667, 0.25      , 0.50847458, 0.45833333],
           [0.19444444, 0.125     , 0.38983051, 0.375     ],
           [0.36111111, 0.29166667, 0.54237288, 0.5       ],
           [0.38888889, 0.41666667, 0.54237288, 0.45833333],
           [0.38888889, 0.375     , 0.54237288, 0.5       ],
           [0.52777778, 0.375     , 0.55932203, 0.5       ],
           [0.22222222, 0.20833333, 0.33898305, 0.41666667],
           [0.38888889, 0.33333333, 0.52542373, 0.5       ],
           [0.55555556, 0.54166667, 0.84745763, 1.        ],
           [0.41666667, 0.29166667, 0.69491525, 0.75      ],
           [0.77777778, 0.41666667, 0.83050847, 0.83333333],
           [0.55555556, 0.375     , 0.77966102, 0.70833333],
           [0.61111111, 0.41666667, 0.81355932, 0.875     ],
           [0.91666667, 0.41666667, 0.94915254, 0.83333333],
           [0.16666667, 0.20833333, 0.59322034, 0.66666667],
           [0.83333333, 0.375     , 0.89830508, 0.70833333],
           [0.66666667, 0.20833333, 0.81355932, 0.70833333],
           [0.80555556, 0.66666667, 0.86440678, 1.        ],
           [0.61111111, 0.5       , 0.69491525, 0.79166667],
           [0.58333333, 0.29166667, 0.72881356, 0.75      ],
           [0.69444444, 0.41666667, 0.76271186, 0.83333333],
           [0.38888889, 0.20833333, 0.6779661 , 0.79166667],
           [0.41666667, 0.33333333, 0.69491525, 0.95833333],
           [0.58333333, 0.5       , 0.72881356, 0.91666667],
           [0.61111111, 0.41666667, 0.76271186, 0.70833333],
           [0.94444444, 0.75      , 0.96610169, 0.875     ],
           [0.94444444, 0.25      , 1.        , 0.91666667],
           [0.47222222, 0.08333333, 0.6779661 , 0.58333333],
           [0.72222222, 0.5       , 0.79661017, 0.91666667],
           [0.36111111, 0.33333333, 0.66101695, 0.79166667],
           [0.94444444, 0.33333333, 0.96610169, 0.79166667],
           [0.55555556, 0.29166667, 0.66101695, 0.70833333],
           [0.66666667, 0.54166667, 0.79661017, 0.83333333],
           [0.80555556, 0.5       , 0.84745763, 0.70833333],
           [0.52777778, 0.33333333, 0.6440678 , 0.70833333],
           [0.5       , 0.41666667, 0.66101695, 0.70833333],
           [0.58333333, 0.33333333, 0.77966102, 0.83333333],
           [0.80555556, 0.41666667, 0.81355932, 0.625     ],
           [0.86111111, 0.33333333, 0.86440678, 0.75      ],
           [1.        , 0.75      , 0.91525424, 0.79166667],
           [0.58333333, 0.33333333, 0.77966102, 0.875     ],
           [0.55555556, 0.33333333, 0.69491525, 0.58333333],
           [0.5       , 0.25      , 0.77966102, 0.54166667],
           [0.94444444, 0.41666667, 0.86440678, 0.91666667],
           [0.55555556, 0.58333333, 0.77966102, 0.95833333],
           [0.58333333, 0.45833333, 0.76271186, 0.70833333],
           [0.47222222, 0.41666667, 0.6440678 , 0.70833333],
           [0.72222222, 0.45833333, 0.74576271, 0.83333333],
           [0.66666667, 0.45833333, 0.77966102, 0.95833333],
           [0.72222222, 0.45833333, 0.69491525, 0.91666667],
           [0.41666667, 0.29166667, 0.69491525, 0.75      ],
           [0.69444444, 0.5       , 0.83050847, 0.91666667],
           [0.66666667, 0.54166667, 0.79661017, 1.        ],
           [0.66666667, 0.41666667, 0.71186441, 0.91666667],
           [0.55555556, 0.20833333, 0.6779661 , 0.75      ],
           [0.61111111, 0.41666667, 0.71186441, 0.79166667],
           [0.52777778, 0.58333333, 0.74576271, 0.91666667],
           [0.44444444, 0.41666667, 0.69491525, 0.70833333]])



## MaxAbsScaler

최대 절대값이 1이 되도록 각 기능을 개별적으로 확장하고 변환

회소성(극한의 값) 파괴하지 않음 

class sklearn.preprocessing.MaxAbsScaler(*, copy=True)


```python
from sklearn.preprocessing import MaxAbsScaler

X = [[ 1., -1.,  2.],
     [ 2.,  0.,  0.],
     [ 0.,  1., -1.]]

transformer = MaxAbsScaler().fit(X)

transformer
MaxAbsScaler()
transformer.transform(X)
```




    array([[ 0.5, -1. ,  1. ],
           [ 1. ,  0. ,  0. ],
           [ 0. ,  1. , -0.5]])


