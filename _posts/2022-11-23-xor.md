---
title:  "[Python] 머신러닝_딥러닝 XOR실습" 

categories:
  - Python
tags:
  - [Python,ADP,machine_learning]

toc: true
toc_sticky: true

date: 2022-11-23

---

```python
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam, SGD
```

# XOR 데이터셋

x1와 x2가 같을땐 0

x1와 x2가 다를땐 1


```python
x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)
y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)
```

## 이진논리회귀(안 풀림)


```python
#y가 하나니깐 dense1
model = Sequential([
  Dense(1, activation='sigmoid')
])

model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))
# 1000번 반복하고 
# verbose=0 결과 출력하지 말라는 뜻
# 만약 verbose=1 출력할 것 
model.fit(x_data, y_data, epochs=1000, verbose=0)
```

    D:\anaconda\lib\site-packages\keras\optimizers\optimizer_v2\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
      super().__init__(name, **kwargs)
    




    <keras.callbacks.History at 0x24ae8073dc0>




```python
# x데이터를 다시 넣어봄 
# 정답은 0 1 1 0인데 다르게 나오는 걸 볼 수 있음 

y_pred = model.predict(x_data)

print(y_pred)
```

    1/1 [==============================] - 0s 69ms/step
    [[0.49811748]
     [0.49966404]
     [0.4997451 ]
     [0.5012917 ]]
    

## 딥러닝(MLP)/Keras-Sequential

Dense(8, activation='relu')

->은닉층 8개+ dense(모든 노드가 연결되어있음) +relu(0이하는 0출력,그외는 y=x)

출력층 1개 y + sigmoide(0-1사이로 나오니깐)


```python
model = Sequential([
  Dense(8, activation='relu'),
  Dense(1, activation='sigmoid'),
])

model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))

model.fit(x_data, y_data, epochs=1000, verbose=0)
```




    <keras.callbacks.History at 0x24aef601d60>




```python
y_pred = model.predict(x_data)

print(y_pred)

# 0 1 1 0에 가까운지 봐야함 
```

    1/1 [==============================] - 0s 49ms/step
    [[0.02010782]
     [0.9909664 ]
     [0.9897775 ]
     [0.00837904]]
    

## 딥러닝(MLP)/Keras-Functional

차이점 

-입력층 크기를 정해줌

from tensorflow.keras.models import Sequential, **Model**

from tensorflow.keras.layers import Dense, **Input**


```python
import numpy as np
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam, SGD
```


```python
input = Input(shape=(2,))
hidden = Dense(8, activation='relu')(input)
output = Dense(1, activation='sigmoid')(hidden)

model = Model(inputs=input, outputs=output)

model.compile(loss='binary_crossentropy', optimizer=SGD(lr=0.1))

model.summary()

#노드의 출력이 2개
#은닉층 8개
#출력층 1개 
#none은 batch size를 의미함(정하기 나름)
```

    Model: "model"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     input_1 (InputLayer)        [(None, 2)]               0         
                                                                     
     dense_3 (Dense)             (None, 8)                 24        
                                                                     
     dense_4 (Dense)             (None, 1)                 9         
                                                                     
    =================================================================
    Total params: 33
    Trainable params: 33
    Non-trainable params: 0
    _________________________________________________________________
    


```python
model.fit(x_data, y_data, epochs=1000, verbose=0)

y_pred = model.predict(x_data)

print(y_pred)
```

    1/1 [==============================] - 0s 43ms/step
    [[0.06621049]
     [0.9884431 ]
     [0.9887888 ]
     [0.00813899]]
    
