---
title:  "[Python] 머신러닝_kaggleQUIZ" 

categories:
  - Python
tags:
  - [Python,ADP,machine_learing]

toc: true
toc_sticky: true

date: 2022-11-09

---
```python
import os
os.environ['KAGGLE_USERNAME'] = 'seungnote' # username
os.environ['KAGGLE_KEY'] = 'bc254ae94554f39d41fcab91537514ad' # key
```

## 연차-연봉 데이터셋 살펴보기 https://www.kaggle.com/rsadiq/salary
```python
!kaggle datasets download -d rsadiq/salary
```

    Downloading salary.zip to D:\anaconda\00.studying
    
    

    
      0%|          | 0.00/392 [00:00<?, ?B/s]
    100%|##########| 392/392 [00:00<?, ?B/s] 
    


```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam, SGD
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import seaborn as sns
from sklearn.model_selection import train_test_split

```


```python
df=pd.read_csv("D:/anaconda/00.studying/salary/Salary.csv")
df.head(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>YearsExperience</th>
      <th>Salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.1</td>
      <td>39343</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.3</td>
      <td>46205</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.5</td>
      <td>37731</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2.0</td>
      <td>43525</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2.2</td>
      <td>39891</td>
    </tr>
  </tbody>
</table>
</div>




```python
print(df.shape)
```

    (35, 2)
    


```python
sns.pairplot(df,x_vars=['YearsExperience'], y_vars=['Salary'],height=4)
```


    
![output_5_1](https://user-images.githubusercontent.com/88616282/200858679-71061a35-d7d9-4da1-b906-97b5bf8bf4d0.png)



```python
x_data=np.array(df[['YearsExperience']],dtype=np.float32)
y_data=np.array(df['Salary'],dtype=np.float32)

print(x_data.shape)
print(y_data.shape)
```

    (35, 1)
    (35,)
    


```python
x_data=x_data.reshape((-1,1))
y_data=y_data.reshape((-1,1))

print(x_data.shape)
print(y_data.shape)
```

    (35, 1)
    (35, 1)
    


```python
x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=2021)

print(x_train.shape, x_val.shape)
print(y_train.shape, y_val.shape)
```

    (28, 1) (7, 1)
    (28, 1) (7, 1)
    


```python
model = Sequential([Dense(1)])

model.compile(loss='mean_squared_error',optimizer=Adam(lr=0.1))


model.fit(
    x_train,
    y_train,
    validation_data=(x_val, y_val),
    epochs=100) 
```

    Epoch 1/100
    

    D:\anaconda\lib\site-packages\keras\optimizers\optimizer_v2\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
      super().__init__(name, **kwargs)
    

    1/1 [==============================] - 1s 980ms/step - loss: 8667728896.0000 - val_loss: 5593320448.0000
    Epoch 2/100
    1/1 [==============================] - 0s 25ms/step - loss: 8667571200.0000 - val_loss: 5593228800.0000
    Epoch 3/100
    1/1 [==============================] - 0s 25ms/step - loss: 8667413504.0000 - val_loss: 5593137664.0000
    Epoch 4/100
    1/1 [==============================] - 0s 27ms/step - loss: 8667254784.0000 - val_loss: 5593046528.0000
    Epoch 5/100
    1/1 [==============================] - 0s 29ms/step - loss: 8667096064.0000 - val_loss: 5592955392.0000
    Epoch 6/100
    1/1 [==============================] - 0s 24ms/step - loss: 8666938368.0000 - val_loss: 5592863744.0000
    Epoch 7/100
    1/1 [==============================] - 0s 30ms/step - loss: 8666778624.0000 - val_loss: 5592772096.0000
    Epoch 8/100
    1/1 [==============================] - 0s 27ms/step - loss: 8666620928.0000 - val_loss: 5592680960.0000
    Epoch 9/100
    1/1 [==============================] - 0s 25ms/step - loss: 8666462208.0000 - val_loss: 5592589312.0000
    Epoch 10/100
    1/1 [==============================] - 0s 29ms/step - loss: 8666304512.0000 - val_loss: 5592498688.0000
    Epoch 11/100
    1/1 [==============================] - 0s 29ms/step - loss: 8666145792.0000 - val_loss: 5592407552.0000
    Epoch 12/100
    1/1 [==============================] - 0s 26ms/step - loss: 8665987072.0000 - val_loss: 5592316416.0000
    Epoch 13/100
    1/1 [==============================] - 0s 27ms/step - loss: 8665828352.0000 - val_loss: 5592224256.0000
    Epoch 14/100
    1/1 [==============================] - 0s 29ms/step - loss: 8665671680.0000 - val_loss: 5592133120.0000
    Epoch 15/100
    1/1 [==============================] - 0s 26ms/step - loss: 8665512960.0000 - val_loss: 5592041984.0000
    Epoch 16/100
    1/1 [==============================] - 0s 25ms/step - loss: 8665355264.0000 - val_loss: 5591950848.0000
    Epoch 17/100
    1/1 [==============================] - 0s 29ms/step - loss: 8665196544.0000 - val_loss: 5591859712.0000
    Epoch 18/100
    1/1 [==============================] - 0s 38ms/step - loss: 8665037824.0000 - val_loss: 5591768064.0000
    Epoch 19/100
    1/1 [==============================] - 0s 28ms/step - loss: 8664880128.0000 - val_loss: 5591677440.0000
    Epoch 20/100
    1/1 [==============================] - 0s 27ms/step - loss: 8664721408.0000 - val_loss: 5591585280.0000
    Epoch 21/100
    1/1 [==============================] - 0s 25ms/step - loss: 8664562688.0000 - val_loss: 5591494656.0000
    Epoch 22/100
    1/1 [==============================] - 0s 27ms/step - loss: 8664404992.0000 - val_loss: 5591403520.0000
    Epoch 23/100
    1/1 [==============================] - 0s 25ms/step - loss: 8664246272.0000 - val_loss: 5591311360.0000
    Epoch 24/100
    1/1 [==============================] - 0s 26ms/step - loss: 8664088576.0000 - val_loss: 5591220736.0000
    Epoch 25/100
    1/1 [==============================] - 0s 27ms/step - loss: 8663929856.0000 - val_loss: 5591129600.0000
    Epoch 26/100
    1/1 [==============================] - 0s 27ms/step - loss: 8663771136.0000 - val_loss: 5591038464.0000
    Epoch 27/100
    1/1 [==============================] - 0s 26ms/step - loss: 8663614464.0000 - val_loss: 5590946816.0000
    Epoch 28/100
    1/1 [==============================] - 0s 29ms/step - loss: 8663454720.0000 - val_loss: 5590855680.0000
    Epoch 29/100
    1/1 [==============================] - 0s 26ms/step - loss: 8663296000.0000 - val_loss: 5590764544.0000
    Epoch 30/100
    1/1 [==============================] - 0s 24ms/step - loss: 8663138304.0000 - val_loss: 5590672384.0000
    Epoch 31/100
    1/1 [==============================] - 0s 29ms/step - loss: 8662980608.0000 - val_loss: 5590581760.0000
    Epoch 32/100
    1/1 [==============================] - 0s 25ms/step - loss: 8662821888.0000 - val_loss: 5590490624.0000
    Epoch 33/100
    1/1 [==============================] - 0s 26ms/step - loss: 8662664192.0000 - val_loss: 5590399488.0000
    Epoch 34/100
    1/1 [==============================] - 0s 27ms/step - loss: 8662505472.0000 - val_loss: 5590307840.0000
    Epoch 35/100
    1/1 [==============================] - 0s 27ms/step - loss: 8662346752.0000 - val_loss: 5590216704.0000
    Epoch 36/100
    1/1 [==============================] - 0s 23ms/step - loss: 8662189056.0000 - val_loss: 5590125568.0000
    Epoch 37/100
    1/1 [==============================] - 0s 28ms/step - loss: 8662030336.0000 - val_loss: 5590033920.0000
    Epoch 38/100
    1/1 [==============================] - 0s 25ms/step - loss: 8661871616.0000 - val_loss: 5589942784.0000
    Epoch 39/100
    1/1 [==============================] - 0s 28ms/step - loss: 8661713920.0000 - val_loss: 5589851648.0000
    Epoch 40/100
    1/1 [==============================] - 0s 28ms/step - loss: 8661556224.0000 - val_loss: 5589760512.0000
    Epoch 41/100
    1/1 [==============================] - 0s 25ms/step - loss: 8661396480.0000 - val_loss: 5589668864.0000
    Epoch 42/100
    1/1 [==============================] - 0s 29ms/step - loss: 8661238784.0000 - val_loss: 5589577728.0000
    Epoch 43/100
    1/1 [==============================] - 0s 27ms/step - loss: 8661081088.0000 - val_loss: 5589486592.0000
    Epoch 44/100
    1/1 [==============================] - 0s 25ms/step - loss: 8660922368.0000 - val_loss: 5589394944.0000
    Epoch 45/100
    1/1 [==============================] - 0s 24ms/step - loss: 8660764672.0000 - val_loss: 5589303808.0000
    Epoch 46/100
    1/1 [==============================] - 0s 24ms/step - loss: 8660605952.0000 - val_loss: 5589213184.0000
    Epoch 47/100
    1/1 [==============================] - 0s 23ms/step - loss: 8660448256.0000 - val_loss: 5589121536.0000
    Epoch 48/100
    1/1 [==============================] - 0s 23ms/step - loss: 8660289536.0000 - val_loss: 5589029888.0000
    Epoch 49/100
    1/1 [==============================] - 0s 25ms/step - loss: 8660130816.0000 - val_loss: 5588938752.0000
    Epoch 50/100
    1/1 [==============================] - 0s 24ms/step - loss: 8659973120.0000 - val_loss: 5588848128.0000
    Epoch 51/100
    1/1 [==============================] - 0s 24ms/step - loss: 8659815424.0000 - val_loss: 5588756992.0000
    Epoch 52/100
    1/1 [==============================] - 0s 22ms/step - loss: 8659656704.0000 - val_loss: 5588665344.0000
    Epoch 53/100
    1/1 [==============================] - 0s 24ms/step - loss: 8659499008.0000 - val_loss: 5588574208.0000
    Epoch 54/100
    1/1 [==============================] - 0s 24ms/step - loss: 8659340288.0000 - val_loss: 5588483072.0000
    Epoch 55/100
    1/1 [==============================] - 0s 24ms/step - loss: 8659181568.0000 - val_loss: 5588391424.0000
    Epoch 56/100
    1/1 [==============================] - 0s 23ms/step - loss: 8659023872.0000 - val_loss: 5588300288.0000
    Epoch 57/100
    1/1 [==============================] - 0s 23ms/step - loss: 8658865152.0000 - val_loss: 5588209152.0000
    Epoch 58/100
    1/1 [==============================] - 0s 24ms/step - loss: 8658707456.0000 - val_loss: 5588118016.0000
    Epoch 59/100
    1/1 [==============================] - 0s 23ms/step - loss: 8658548736.0000 - val_loss: 5588026368.0000
    Epoch 60/100
    1/1 [==============================] - 0s 23ms/step - loss: 8658391040.0000 - val_loss: 5587935232.0000
    Epoch 61/100
    1/1 [==============================] - 0s 22ms/step - loss: 8658233344.0000 - val_loss: 5587844096.0000
    Epoch 62/100
    1/1 [==============================] - 0s 23ms/step - loss: 8658074624.0000 - val_loss: 5587752448.0000
    Epoch 63/100
    1/1 [==============================] - 0s 22ms/step - loss: 8657916928.0000 - val_loss: 5587661824.0000
    Epoch 64/100
    1/1 [==============================] - 0s 24ms/step - loss: 8657758208.0000 - val_loss: 5587570688.0000
    Epoch 65/100
    1/1 [==============================] - 0s 23ms/step - loss: 8657599488.0000 - val_loss: 5587479552.0000
    Epoch 66/100
    1/1 [==============================] - 0s 24ms/step - loss: 8657441792.0000 - val_loss: 5587387904.0000
    Epoch 67/100
    1/1 [==============================] - 0s 23ms/step - loss: 8657283072.0000 - val_loss: 5587297280.0000
    Epoch 68/100
    1/1 [==============================] - 0s 24ms/step - loss: 8657125376.0000 - val_loss: 5587206144.0000
    Epoch 69/100
    1/1 [==============================] - 0s 23ms/step - loss: 8656967680.0000 - val_loss: 5587115008.0000
    Epoch 70/100
    1/1 [==============================] - 0s 23ms/step - loss: 8656808960.0000 - val_loss: 5587022848.0000
    Epoch 71/100
    1/1 [==============================] - 0s 24ms/step - loss: 8656650240.0000 - val_loss: 5586932224.0000
    Epoch 72/100
    1/1 [==============================] - 0s 25ms/step - loss: 8656492544.0000 - val_loss: 5586841088.0000
    Epoch 73/100
    1/1 [==============================] - 0s 24ms/step - loss: 8656333824.0000 - val_loss: 5586749952.0000
    Epoch 74/100
    1/1 [==============================] - 0s 24ms/step - loss: 8656176128.0000 - val_loss: 5586658304.0000
    Epoch 75/100
    1/1 [==============================] - 0s 23ms/step - loss: 8656017408.0000 - val_loss: 5586567168.0000
    Epoch 76/100
    1/1 [==============================] - 0s 25ms/step - loss: 8655858688.0000 - val_loss: 5586476032.0000
    Epoch 77/100
    1/1 [==============================] - 0s 22ms/step - loss: 8655700992.0000 - val_loss: 5586384384.0000
    Epoch 78/100
    1/1 [==============================] - 0s 24ms/step - loss: 8655543296.0000 - val_loss: 5586293248.0000
    Epoch 79/100
    1/1 [==============================] - 0s 24ms/step - loss: 8655384576.0000 - val_loss: 5586202624.0000
    Epoch 80/100
    1/1 [==============================] - 0s 25ms/step - loss: 8655226880.0000 - val_loss: 5586110976.0000
    Epoch 81/100
    1/1 [==============================] - 0s 23ms/step - loss: 8655068160.0000 - val_loss: 5586019840.0000
    Epoch 82/100
    1/1 [==============================] - 0s 24ms/step - loss: 8654910464.0000 - val_loss: 5585928704.0000
    Epoch 83/100
    1/1 [==============================] - 0s 23ms/step - loss: 8654751744.0000 - val_loss: 5585837568.0000
    Epoch 84/100
    1/1 [==============================] - 0s 23ms/step - loss: 8654594048.0000 - val_loss: 5585746432.0000
    Epoch 85/100
    1/1 [==============================] - 0s 24ms/step - loss: 8654436352.0000 - val_loss: 5585654784.0000
    Epoch 86/100
    1/1 [==============================] - 0s 23ms/step - loss: 8654277632.0000 - val_loss: 5585564160.0000
    Epoch 87/100
    1/1 [==============================] - 0s 22ms/step - loss: 8654119936.0000 - val_loss: 5585472512.0000
    Epoch 88/100
    1/1 [==============================] - 0s 23ms/step - loss: 8653961216.0000 - val_loss: 5585381888.0000
    Epoch 89/100
    1/1 [==============================] - 0s 22ms/step - loss: 8653802496.0000 - val_loss: 5585290240.0000
    Epoch 90/100
    1/1 [==============================] - 0s 23ms/step - loss: 8653644800.0000 - val_loss: 5585199104.0000
    Epoch 91/100
    1/1 [==============================] - 0s 24ms/step - loss: 8653487104.0000 - val_loss: 5585107968.0000
    Epoch 92/100
    1/1 [==============================] - 0s 24ms/step - loss: 8653329408.0000 - val_loss: 5585016320.0000
    Epoch 93/100
    1/1 [==============================] - 0s 24ms/step - loss: 8653170688.0000 - val_loss: 5584925184.0000
    Epoch 94/100
    1/1 [==============================] - 0s 22ms/step - loss: 8653011968.0000 - val_loss: 5584834048.0000
    Epoch 95/100
    1/1 [==============================] - 0s 24ms/step - loss: 8652854272.0000 - val_loss: 5584742912.0000
    Epoch 96/100
    1/1 [==============================] - 0s 23ms/step - loss: 8652696576.0000 - val_loss: 5584651776.0000
    Epoch 97/100
    1/1 [==============================] - 0s 23ms/step - loss: 8652537856.0000 - val_loss: 5584560640.0000
    Epoch 98/100
    1/1 [==============================] - 0s 23ms/step - loss: 8652380160.0000 - val_loss: 5584470016.0000
    Epoch 99/100
    1/1 [==============================] - 0s 23ms/step - loss: 8652221440.0000 - val_loss: 5584378880.0000
    Epoch 100/100
    1/1 [==============================] - 0s 22ms/step - loss: 8652063744.0000 - val_loss: 5584287232.0000
    




    <keras.callbacks.History at 0x18b70bc1970>




```python
y_pred=model.predict(x_val)

plt.scatter(x_val,y_val)
plt.scatter(x_val,y_pred,color='r') #예측값은 빨간색. 가설은 선형이라서 
plt.show()
```

    
![output_10_1](https://user-images.githubusercontent.com/88616282/200858742-d420e939-ea10-48e5-bd28-f50961872ee4.png)


## Learning rate(lr)를 바꾸면서 실험하기
## Optimizer를 바꾸면서 실험하기
## 손실함수(loss)를 mean_absolute_error 로 바꿔서 실험하기

optimizer= **최적 구간에 도달하기 위한 걸음 방향
걸음방법을 다르게하고 학습률lr 보폭을 조절하면서 최적의 구간에 도달하려고함

**데이터셋에 맞는 optimizer를 찾는거 중요

** SGD: 모든 방향을 탐색하지 않고 확률에 기반해서 몇몇곳만 빠르게 가봄
** Adam: 보폭과 방향을 적절하게 잘 분배함. 과거 맥박을 기준으로 올바른 방향을 찾아감 

![307bc8cd-f05a-48d5-8adb-ddeedf76b7651](https://user-images.githubusercontent.com/88616282/201087875-ea61d85a-da2f-482a-8183-a189e11630f0.png)

```python

model = Sequential([Dense(1)])


model.compile(loss='mean_squared_error',optimizer=SGD(lr=0.01))


model.fit(
    x_train,
    y_train,
    validation_data=(x_val, y_val),
    epochs=100) 
```

    Epoch 1/100
    

    D:\anaconda\lib\site-packages\keras\optimizers\optimizer_v2\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
      super().__init__(name, **kwargs)
    

    1/1 [==============================] - 1s 506ms/step - loss: 8666956800.0000 - val_loss: 144187632.0000
    Epoch 2/100
    1/1 [==============================] - 0s 46ms/step - loss: 520592704.0000 - val_loss: 311874528.0000
    Epoch 3/100
    1/1 [==============================] - 0s 25ms/step - loss: 218535968.0000 - val_loss: 245429104.0000
    Epoch 4/100
    1/1 [==============================] - 0s 28ms/step - loss: 205774592.0000 - val_loss: 254774928.0000
    Epoch 5/100
    1/1 [==============================] - 0s 23ms/step - loss: 203697152.0000 - val_loss: 250786160.0000
    Epoch 6/100
    1/1 [==============================] - 0s 25ms/step - loss: 202028784.0000 - val_loss: 249410720.0000
    Epoch 7/100
    1/1 [==============================] - 0s 26ms/step - loss: 200390560.0000 - val_loss: 247557024.0000
    Epoch 8/100
    1/1 [==============================] - 0s 22ms/step - loss: 198768240.0000 - val_loss: 245814784.0000
    Epoch 9/100
    1/1 [==============================] - 0s 27ms/step - loss: 197161264.0000 - val_loss: 244071200.0000
    Epoch 10/100
    1/1 [==============================] - 0s 22ms/step - loss: 195569584.0000 - val_loss: 242347408.0000
    Epoch 11/100
    1/1 [==============================] - 0s 30ms/step - loss: 193992848.0000 - val_loss: 240639248.0000
    Epoch 12/100
    1/1 [==============================] - 0s 26ms/step - loss: 192430960.0000 - val_loss: 238947440.0000
    Epoch 13/100
    1/1 [==============================] - 0s 23ms/step - loss: 190883760.0000 - val_loss: 237271376.0000
    Epoch 14/100
    1/1 [==============================] - 0s 27ms/step - loss: 189351248.0000 - val_loss: 235611264.0000
    Epoch 15/100
    1/1 [==============================] - 0s 24ms/step - loss: 187833168.0000 - val_loss: 233966864.0000
    Epoch 16/100
    1/1 [==============================] - 0s 30ms/step - loss: 186329456.0000 - val_loss: 232337936.0000
    Epoch 17/100
    1/1 [==============================] - 0s 28ms/step - loss: 184839856.0000 - val_loss: 230724368.0000
    Epoch 18/100
    1/1 [==============================] - 0s 24ms/step - loss: 183364352.0000 - val_loss: 229126128.0000
    Epoch 19/100
    1/1 [==============================] - 0s 26ms/step - loss: 181902816.0000 - val_loss: 227542816.0000
    Epoch 20/100
    1/1 [==============================] - 0s 25ms/step - loss: 180454944.0000 - val_loss: 225974688.0000
    Epoch 21/100
    1/1 [==============================] - 0s 25ms/step - loss: 179020832.0000 - val_loss: 224421152.0000
    Epoch 22/100
    1/1 [==============================] - 0s 28ms/step - loss: 177600256.0000 - val_loss: 222882464.0000
    Epoch 23/100
    1/1 [==============================] - 0s 24ms/step - loss: 176193040.0000 - val_loss: 221358208.0000
    Epoch 24/100
    1/1 [==============================] - 0s 26ms/step - loss: 174799072.0000 - val_loss: 219848336.0000
    Epoch 25/100
    1/1 [==============================] - 0s 27ms/step - loss: 173418320.0000 - val_loss: 218352784.0000
    Epoch 26/100
    1/1 [==============================] - 0s 24ms/step - loss: 172050544.0000 - val_loss: 216871168.0000
    Epoch 27/100
    1/1 [==============================] - 0s 24ms/step - loss: 170695680.0000 - val_loss: 215403760.0000
    Epoch 28/100
    1/1 [==============================] - 0s 23ms/step - loss: 169353616.0000 - val_loss: 213950112.0000
    Epoch 29/100
    1/1 [==============================] - 0s 24ms/step - loss: 168024240.0000 - val_loss: 212510304.0000
    Epoch 30/100
    1/1 [==============================] - 0s 23ms/step - loss: 166707344.0000 - val_loss: 211083952.0000
    Epoch 31/100
    1/1 [==============================] - 0s 26ms/step - loss: 165402928.0000 - val_loss: 209671136.0000
    Epoch 32/100
    1/1 [==============================] - 0s 24ms/step - loss: 164110848.0000 - val_loss: 208271520.0000
    Epoch 33/100
    1/1 [==============================] - 0s 24ms/step - loss: 162830848.0000 - val_loss: 206885264.0000
    Epoch 34/100
    1/1 [==============================] - 0s 27ms/step - loss: 161562960.0000 - val_loss: 205512048.0000
    Epoch 35/100
    1/1 [==============================] - 0s 25ms/step - loss: 160307088.0000 - val_loss: 204151904.0000
    Epoch 36/100
    1/1 [==============================] - 0s 25ms/step - loss: 159063040.0000 - val_loss: 202804528.0000
    Epoch 37/100
    1/1 [==============================] - 0s 25ms/step - loss: 157830768.0000 - val_loss: 201469968.0000
    Epoch 38/100
    1/1 [==============================] - 0s 24ms/step - loss: 156610016.0000 - val_loss: 200147760.0000
    Epoch 39/100
    1/1 [==============================] - 0s 26ms/step - loss: 155400880.0000 - val_loss: 198838240.0000
    Epoch 40/100
    1/1 [==============================] - 0s 24ms/step - loss: 154203088.0000 - val_loss: 197541072.0000
    Epoch 41/100
    1/1 [==============================] - 0s 26ms/step - loss: 153016672.0000 - val_loss: 196256144.0000
    Epoch 42/100
    1/1 [==============================] - 0s 23ms/step - loss: 151841376.0000 - val_loss: 194983312.0000
    Epoch 43/100
    1/1 [==============================] - 0s 32ms/step - loss: 150677184.0000 - val_loss: 193722576.0000
    Epoch 44/100
    1/1 [==============================] - 0s 26ms/step - loss: 149524016.0000 - val_loss: 192473680.0000
    Epoch 45/100
    1/1 [==============================] - 0s 22ms/step - loss: 148381712.0000 - val_loss: 191236560.0000
    Epoch 46/100
    1/1 [==============================] - 0s 25ms/step - loss: 147250160.0000 - val_loss: 190011232.0000
    Epoch 47/100
    1/1 [==============================] - 0s 23ms/step - loss: 146129312.0000 - val_loss: 188797312.0000
    Epoch 48/100
    1/1 [==============================] - 0s 25ms/step - loss: 145019024.0000 - val_loss: 187595008.0000
    Epoch 49/100
    1/1 [==============================] - 0s 23ms/step - loss: 143919232.0000 - val_loss: 186404000.0000
    Epoch 50/100
    1/1 [==============================] - 0s 23ms/step - loss: 142829728.0000 - val_loss: 185224176.0000
    Epoch 51/100
    1/1 [==============================] - 0s 23ms/step - loss: 141750624.0000 - val_loss: 184055520.0000
    Epoch 52/100
    1/1 [==============================] - 0s 26ms/step - loss: 140681648.0000 - val_loss: 182898000.0000
    Epoch 53/100
    1/1 [==============================] - 0s 22ms/step - loss: 139622768.0000 - val_loss: 181751280.0000
    Epoch 54/100
    1/1 [==============================] - 0s 27ms/step - loss: 138573856.0000 - val_loss: 180615520.0000
    Epoch 55/100
    1/1 [==============================] - 0s 25ms/step - loss: 137534864.0000 - val_loss: 179490384.0000
    Epoch 56/100
    1/1 [==============================] - 0s 24ms/step - loss: 136505696.0000 - val_loss: 178375888.0000
    Epoch 57/100
    1/1 [==============================] - 0s 26ms/step - loss: 135486208.0000 - val_loss: 177272016.0000
    Epoch 58/100
    1/1 [==============================] - 0s 23ms/step - loss: 134476320.0000 - val_loss: 176178432.0000
    Epoch 59/100
    1/1 [==============================] - 0s 25ms/step - loss: 133475944.0000 - val_loss: 175095312.0000
    Epoch 60/100
    1/1 [==============================] - 0s 29ms/step - loss: 132485104.0000 - val_loss: 174022256.0000
    Epoch 61/100
    1/1 [==============================] - 0s 23ms/step - loss: 131503496.0000 - val_loss: 172959440.0000
    Epoch 62/100
    1/1 [==============================] - 0s 24ms/step - loss: 130531216.0000 - val_loss: 171906688.0000
    Epoch 63/100
    1/1 [==============================] - 0s 24ms/step - loss: 129568104.0000 - val_loss: 170863760.0000
    Epoch 64/100
    1/1 [==============================] - 0s 27ms/step - loss: 128614040.0000 - val_loss: 169830880.0000
    Epoch 65/100
    1/1 [==============================] - 0s 23ms/step - loss: 127669032.0000 - val_loss: 168807568.0000
    Epoch 66/100
    1/1 [==============================] - 0s 26ms/step - loss: 126732944.0000 - val_loss: 167793968.0000
    Epoch 67/100
    1/1 [==============================] - 0s 23ms/step - loss: 125805624.0000 - val_loss: 166789968.0000
    Epoch 68/100
    1/1 [==============================] - 0s 25ms/step - loss: 124887064.0000 - val_loss: 165795456.0000
    Epoch 69/100
    1/1 [==============================] - 0s 23ms/step - loss: 123977240.0000 - val_loss: 164810272.0000
    Epoch 70/100
    1/1 [==============================] - 0s 26ms/step - loss: 123075928.0000 - val_loss: 163834480.0000
    Epoch 71/100
    1/1 [==============================] - 0s 24ms/step - loss: 122183168.0000 - val_loss: 162867808.0000
    Epoch 72/100
    1/1 [==============================] - 0s 27ms/step - loss: 121298776.0000 - val_loss: 161910400.0000
    Epoch 73/100
    1/1 [==============================] - 0s 28ms/step - loss: 120422768.0000 - val_loss: 160961968.0000
    Epoch 74/100
    1/1 [==============================] - 0s 23ms/step - loss: 119555064.0000 - val_loss: 160022528.0000
    Epoch 75/100
    1/1 [==============================] - 0s 24ms/step - loss: 118695480.0000 - val_loss: 159091840.0000
    Epoch 76/100
    1/1 [==============================] - 0s 25ms/step - loss: 117844048.0000 - val_loss: 158170096.0000
    Epoch 77/100
    1/1 [==============================] - 0s 24ms/step - loss: 117000616.0000 - val_loss: 157256912.0000
    Epoch 78/100
    1/1 [==============================] - 0s 24ms/step - loss: 116165160.0000 - val_loss: 156352416.0000
    Epoch 79/100
    1/1 [==============================] - 0s 23ms/step - loss: 115337584.0000 - val_loss: 155456528.0000
    Epoch 80/100
    1/1 [==============================] - 0s 26ms/step - loss: 114517816.0000 - val_loss: 154568992.0000
    Epoch 81/100
    1/1 [==============================] - 0s 24ms/step - loss: 113705728.0000 - val_loss: 153689904.0000
    Epoch 82/100
    1/1 [==============================] - 0s 27ms/step - loss: 112901392.0000 - val_loss: 152819152.0000
    Epoch 83/100
    1/1 [==============================] - 0s 23ms/step - loss: 112104592.0000 - val_loss: 151956640.0000
    Epoch 84/100
    1/1 [==============================] - 0s 25ms/step - loss: 111315376.0000 - val_loss: 151102192.0000
    Epoch 85/100
    1/1 [==============================] - 0s 24ms/step - loss: 110533544.0000 - val_loss: 150255792.0000
    Epoch 86/100
    1/1 [==============================] - 0s 23ms/step - loss: 109759096.0000 - val_loss: 149417456.0000
    Epoch 87/100
    1/1 [==============================] - 0s 22ms/step - loss: 108991952.0000 - val_loss: 148587072.0000
    Epoch 88/100
    1/1 [==============================] - 0s 24ms/step - loss: 108232088.0000 - val_loss: 147764464.0000
    Epoch 89/100
    1/1 [==============================] - 0s 24ms/step - loss: 107479304.0000 - val_loss: 146949552.0000
    Epoch 90/100
    1/1 [==============================] - 0s 23ms/step - loss: 106733656.0000 - val_loss: 146142496.0000
    Epoch 91/100
    1/1 [==============================] - 0s 23ms/step - loss: 105995088.0000 - val_loss: 145342960.0000
    Epoch 92/100
    1/1 [==============================] - 0s 25ms/step - loss: 105263464.0000 - val_loss: 144551088.0000
    Epoch 93/100
    1/1 [==============================] - 0s 23ms/step - loss: 104538712.0000 - val_loss: 143766576.0000
    Epoch 94/100
    1/1 [==============================] - 0s 23ms/step - loss: 103820848.0000 - val_loss: 142989488.0000
    Epoch 95/100
    1/1 [==============================] - 0s 24ms/step - loss: 103109744.0000 - val_loss: 142219824.0000
    Epoch 96/100
    1/1 [==============================] - 0s 25ms/step - loss: 102405320.0000 - val_loss: 141457280.0000
    Epoch 97/100
    1/1 [==============================] - 0s 27ms/step - loss: 101707584.0000 - val_loss: 140702112.0000
    Epoch 98/100
    1/1 [==============================] - 0s 23ms/step - loss: 101016432.0000 - val_loss: 139953984.0000
    Epoch 99/100
    1/1 [==============================] - 0s 25ms/step - loss: 100331728.0000 - val_loss: 139212928.0000
    Epoch 100/100
    1/1 [==============================] - 0s 22ms/step - loss: 99653576.0000 - val_loss: 138478928.0000
    




    <keras.callbacks.History at 0x18b795b10d0>




```python
y_pred = model.predict(x_val)

plt.scatter(x_val, y_val)
plt.scatter(x_val, y_pred, color='r')
plt.show()
```
![output_12_1](https://user-images.githubusercontent.com/88616282/200858898-386dc8ee-6907-4cf2-b8c5-e09ee7acfe93.png)


